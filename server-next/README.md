# Indexify 

## Stateful Compute Engine for building Agentic Applications and Data-Intensive Workflows

Indexify offers a low-cost abstraction for building workflows that models Agentic state machines and Data pipelines. The workflows are deployed as live API endpoints. Application and Business logic are expressed as ***Functions*** while Dataflow across them are defined as ***Graphs***.

### Key Features

Indexify gives you the following features out of the box,

* **Dynamic Dataflow**: Indexify supports dynamic dataflow branching and cycles between ***Functions*** of a ***Graph***.

* **Parallel Execution**: Automatically distributes workflows across many machines, using a control-plane -- data-plane architecture.

* **Placement Constraints**: Graphs can span across GPU instances and cost-effective CPU machines. Functions can be constrainted to specific instance types if required. 

* **Request Queuing and Batching**: Automatically batch parallel workflow invocations and maximize GPU utilization.

* **Output Checkpoints**: Automatically checkpoint intermediate outputs to quickly resume failed Graph stages.

### Use-cases
Workflows structured as Graphs enable many interesting use-cases -

- **Document Processing and Indexing Pipelines**

- **Audio Transcription, Summarization and Indexing APIs**

- **Web Scraping and Structured Extraction Pipelines**

- **Multi-Stage-Retrieval APIs for Advanced RAG**


## Install 
```bash
pip install indexify
```

## Basic Usage 

Workflows are written as Python functions and laid out as Graphs. Functions in a Graph are automatically invoked when upstream functions finishes with their output.

API calls to workflows are automatically queued, failures are retried so you don't have to spend your time designing for reliability. There is no need to use RPC libraries, Kafka or other databases to store internal state and communicate between functions across process/machine boundaries.

#### Write a Workflow 
```python
from pydantic import BaseModel

class Sum(BaseModel):
    val: int

@indexify_function(retries=3)
def generate_sequence(a: int) -> List[int]:
    return [i for i in range(a)]

@indexify_function(init_value=Sum)
def sum_all_numbers(sum: Sum, val: int) -> Sum:
    return Sum(sum.val + val)

@indexify_function(placement_constraints="python_ver>3.8 and os=linux")
def display(sum: Sum) -> str:
    return f"value of sequence: f{sum.val}"

from indexify import ComputeGraph
g = ComputeGraph(name="sequence_summer", start_node=generate_sequence, description="Simple Sequence Summer")
g.add_edge(generate_sequence, sum_all_numbers)
g.add_edge(sum_all_numbers, display)
```

#### Register and Invoke the Compute Graph 
```python
from indexify import create_client 
client = create_client(ephemeral=True)
client.register_compute_graph(g)

client.invoke_workflow_with_object("sequence_summer", a=10)
result = client.graph_outputs("sequence_summer", "display")
print(result)
```

This is it! You have built and your first multi-stage workflow locally! 

#### Automatic Parallelization 

When a function returns a `List` the downstream function is automatically called in parallel with all the elements of the list.

```python
def func_a(..) -> List[int]:
    pass

def func_b(..) -> SomeValue:
    pass
```

Here, `func_b` will be invoked in parallel with every output of `func_a`. There is no need to use Ray, Spark or Dask for parallelization when an upstream function produces a sequence of values.

**Use Cases:** - Generating Embedding from every single chunk of a workflow.

#### Reducing/Accumulating from Sequences

```python
def func_a(..) -> List[int]:
    pass

class SomeValue:
    foo

def func_b(val: SomeValue, ..) -> SomeValue:
    pass
```

Here, `func_b` will be called serially with every value generated by `func_a`. The previous `SomeValue` produced by `func_b` will be injected in every subsequent calls. This allows to incrementally build state from a sequence generated by upstream functions.

**Use Cases:** - Producing a single summary from scraping 100s of web pages on a specific topic.

#### Create a Graph Endpoint HTTP API  

Indexify comes with a server for deploying Compute Graphs as an API so they can be called from other applications or systems.

```bash
indexify-cli run-server
```

This starts the Indexify Server and an Executor - 

**Indexify Server**: Manages state of your graphs when they are called. It stores the outputs of the functions and calls them based on the structure of the graph. 

**Executor**: Runs the python functions which are part of your Graph.

Change the code above to deploy the graph as an API on the server -

```python
client = create_client() # Remove ephemeral=True
client.register_compute_graph(g) # Same as above
```

This serializes your Graph code and uploads it to the server, and instantiates a new endpoint.

Everything else, remains the same in your application code that invokes the Graph to process data and retrieve outputs! 

**What happens when you invoke a Compute Graph API?**

* Indexify serializes the input and calls the API over HTTP. 

* The server creates and schedules a Task for the fist function on an executor.

* The executor loads and executes the function and sends the data back to the server.

* The two above steps are executed for every function in the Graph. 

#### Distributed Execution by Design 

**Parallel Execution** - You can run as many executors you want on a single machine or on many 100s of machines. This will enable Indexify Server to run your graphs in parallel if they are invoked 1000s of times concurrently. 

**Placement Constraints** - You can make functions on the graph be executed on different classes of machines.

## Programming Model 

#### Automatic Parallelization 

When a function returns a `List` the downstream function is automatically called in parallel with all the elements of the list.

```python
def func_a(..) -> List[int]:
    pass

def func_b(..) -> SomeValue:
    pass
```

In the above example calls to `func_b` will be automatically parallelized from the outputs of `func_a`. 

**Use Cases:** - Generating Embedding from every single chunk of a workflow.

#### Reducing/Accumulating from Sequences

```python
def func_a(..) -> List[int]:
    pass

class SomeValue:
    foo

def func_b(val: SomeValue, ..) -> SomeValue:
    pass
```

In this example, `func_b` will be called serially for every value generated by `func_a`, and the previous `SomeValue` returned will 
be injected in the function. This allows to incrementally build state from a sequence generated by upstream functions.

**Use Cases:** - Producing a single summary from scraping 100s of web pages on a specific topic.
