---
title: Indexify
description: Compute Engine for Building and Serving Multi-Stage Data-Intensive Workflows
---
Indexify is a compute framework for building durable data-intensive workflows and serving them as APIs. 
The workflows are elastic, functions run in paralellel across mutliple machines, automatically managing data flow between dependent 
functions. The Graphs are served as live API endpoints for seamless integration with existing systems.

## Key Features
* **Conditional Branching and Data Flow:** Router functions can dynamically chose one or more edges in Graph making it easy to invoke expert models based on inputs.
* **Local Inference:** Run LLMs in workflow functions using LLamaCPP, vLLM, or Hugging Face Transformers.
* **Distributed Map and Reduce:** Automatically parallelizes functions over sequences across multiple machines. Reducer functions are durable and invoked as map functions finish.
* **Version Graphs and Backfill:** Backfill API to update previously processed data when functions or models are updated.
* **Request Queuing and Batching:** Automatically queues and batches parallel workflow invocations to maximize GPU utilization.

<Note>
While traditional workflows were often linear, we chose a graph-based approach to unlock inherent parallelism in AI tasks such as 
embeddings, chunking, summarization, object detection, and transcription.
</Note>

<video
  autoPlay
  muted
  loop
  controls
  className="w-full aspect-video"
  src="https://pub-cda17134527d47a3b08825f7328a9295.r2.dev/final_website_recording.mp4"
></video>
*A webscraper and summarizer workflow built using Indexify.*

## Quick Start

Let's create a simple workflow to summarize a website on-demand! It demonstrates how to build and serve a workflow as a **remote** Python API.

<Steps>
  <Step title="Install">
    Install the Indexify SDK.
    ```bash
    pip install indexify
    ```
  </Step>
  <Step title="Define the Graph">
    We will write two functions, `scrape_website` and `summarize_text`.
    We create a Graph `website-summarizer` that executes the scrape function, and then executes the summarizer with the outputs of the scraper.

    ```python
    from indexify import indexify_function, Graph

    @indexify_function()
    def scrape_website(url: str) -> str:
        import requests
        return requests.get(f"http://r.jina.ai/{url}").text

    @indexify_function()
    def summarize_text(text: str) -> str:
        from openai import OpenAI
        completion = OpenAI().chat.completiions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "You are a helpful assistant. Generate a summary of this website"},
                {"role": "user", "content": text},
            ],
        )
        return completion.choices[0].message.content

    g = Graph(name="website-summarizer", start_node=scrape_website)
    g.add_edge(scrape_website, summarize_text)
    ```
  </Step>
  <Step title="Test the Graph In-Process">
    The graph can be run as-is, this is useful for testing.

    ```python
    g.run(url="https://en.wikipedia.org/wiki/Golden_State_Warriors")
    ```
  </Step>
  <Step title="Deploying a Graph as an Remote API">
    When it's time to consume your graph from other applications, you can serve it as an API. You can run the server in production in many ways, but here we run this in our laptop to show how it works.

    ```bash
    indexify-cli server-dev-mode
    ```

    This starts the following processes -
    * **Server:** Orchestrates functions in the graph, stores execution state, and hosts Remote Graph APIs.
    * **Executor:** Runs the individual functions in the graph.

    Once the server is ready, you can deploy the graph -
    ```python
    from indexify import RemoteGraph
    RemoteGraph.deploy(g, server_url="http://localhost:8900")
    ```
  </Step>
  <Step title="Call a Graph Endpoint">
    Once the graph is deployed, you can get a reference of the Graph in any application.
    ```python
    graph = RemoteGraph.by_name(name="website-summarizer", server_url="http://localhost:8900")
    ```

    You can now call the graph as a remote API.
    ```python
    invocation_id = graph.run(blocking_until_done=True, url="https://en.wikipedia.org/wiki/Golden_State_Warriors")
    results = graph.output(invocation_id)
    ```
  </Step>
</Steps>

## Why Indexify?
LLM applications require a deep understanding of business context and enterprise data. Developers often need to design complex 
algorithms with multiple, sometimes parallel, steps. While interacting with models isn't the most challenging aspect, 
several hurdles arise when moving from a prototype to a production-ready service:

* **State Management**: Sharing and persisting the state of dependent stages in your application.
* **API Integration**: Serving the application as an API for seamless integration with other company systems.
* **Version Control and Data Migration**: As models evolve, developers must version workflow code and re-process existing data with newer models (e.g., improved structured extraction, summarization, or embedding models).
* **Compound Systems**: Applications often require multiple models based on input context, necessitating dynamic routing of data to different functions. For instance, different document extraction models might be optimal for specific layouts, requiring a modular workflow that can adapt to various input types and contexts.
* **Hardware Optimization**: For local inference using open-source or custom-trained models, efficiently utilizing GPUs for model inference and CPUs for other workflow components.
* **Resource Management**: Batching data across various workflows on GPU machines for optimal performance.

Building such a system requires expertise in stateful distributed systems and time consuming. Indexify addresses these challenges by:

* Providing graphs as remote APIs
* Enabling distributed execution on heterogeneous machines
* Implementing retries and request queuing
* Durable workflow state
* Offering code versioning and data backfill capabilities

With Indexify, developers can program workflows as if they were running on a single machine, while benefiting from a robust, distributed infrastructure.

<Card title="Key Concepts" icon="link" href="key-concepts">
Learn about the key concepts in Indexify, such as Graphs, Functions, and Images.
</Card>
<Card title="Packaging Dependencies" icon="link" href="packaging-dependencies">
  A detailed example of text, table and image extraction from PDF. It also covers building image and text indexes and doing
  cross-modal retrieval, re-ranking, and reciproal rank fusion.
</Card>
<Card title="Deployment" icon="link" href="operations/deployment">
Deployment of Indexify in various environments - Bare Metal, Docker Compose, and Kubernetes.
</Card>
